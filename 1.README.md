**Problem Statement & Motivation**

Investment decisions in venture capital are often highly subjective, influenced by personal biases, limited information, and inconsistent evaluation criteria. Startups at the early stage are typically assessed based on a mix of financial health, perceived market opportunity, and qualitative factors like team strength, idea novelty, and market sentiment.

However, human judgment alone suffers from key limitations:

Bias & heuristics — Investors may unconsciously favor certain industries, geographies, or founder profiles.

Inconsistent criteria — Evaluation standards vary between firms and even individual partners.

Information asymmetry — Early-stage startups often lack extensive financial history, making quantitative comparisons difficult.

Overweighting hype — Market sentiment and trends can overshadow long-term viability.

These challenges can lead to missed opportunities (false negatives) or poor investments (false positives).

**Where This Can Be Utilised**

The Machine Learning–Driven Startup Investment Readiness Model addresses these gaps by quantifying readiness through a structured, data-driven approach that combines:

Financial metrics — Runway, burn rate, ARR, LTV/CAC, churn, etc.

Strategic indicators — Idea novelty (SBERT similarity), sustainability alignment with UN SDGs.

Perceptual measures — FinBERT sentiment analysis of news coverage, social buzz metrics.

Potential applications include:

Venture Capital Firms — As a screening tool to rank startups before partner review.

Accelerators & Incubators — To evaluate applicant readiness objectively.

Corporate Innovation Teams — To assess potential partnership or acquisition targets.

Startup Funding Platforms — To provide readiness scores to investors for informed decision-making.

Government/Policy Programs — To identify and prioritize startups for grants or subsidies.

**Motive to Solve**

The motive behind solving this problem is to:

Reduce subjectivity in venture funding decisions by introducing quantifiable, explainable metrics.

Improve consistency in evaluation across industries, geographies, and investment stages.

Support early-stage founders in identifying gaps in their readiness before pitching.

Enhance investor efficiency by narrowing the funnel to high-potential candidates.

Promote fairness and inclusivity by mitigating biases in the evaluation process.

Ultimately, the goal is to create a decision-support system that empowers both investors and entrepreneurs, aligning capital allocation more closely with genuine market and execution potential.

## **1️ Problem Formulation**

We want to predict **investment readiness** $y \in \{0,1\}$ of a startup based on a set of **15 engineered features** $x \in \mathbb{R}^{15}$ from three domains:

$$
x = [x_\text{financial}, x_\text{strategic}, x_\text{perceptual}]
$$

The goal is to model:

$$
\hat{y} = f(x) = 
\begin{cases}
1, & \text{if startup is investment ready} \\
0, & \text{otherwise}
\end{cases}
$$

---

## **2️ Feature Engineering Mathematics**

### **(a) Financial Features**

These are mostly **normalized numerical KPIs** like funding, runway, LTV/CAC ratio, etc.
Some derived metrics:

1. **Runway (months)**:

$$
\text{Runway} = \frac{\text{Total Funding}}{\text{Monthly Burn Rate}}
$$

2. **LTV/CAC Ratio**:

$$
\text{LTV\ CAC} = \frac{\text{LTV}}{\text{CAC}}
$$

3. **ARR (Annual Recurring Revenue)**:

$$
\text{ARR} = \text{Monthly Revenue} \times 12
$$

---

### **(b) Strategic Features**

#### **Idea Novelty Score (SBERT + Cosine Similarity)**

Given:

* $e_s$ = SBERT embedding of startup description
* $e_m^{(i)}$ = embedding of the $i$-th market idea

**Cosine Similarity**:

$$
\cos(e_s, e_m^{(i)}) = \frac{e_s \cdot e_m^{(i)}}{\| e_s \| \, \| e_m^{(i)} \|}
$$

Novelty score is:

$$
\text{Novelty} = 1 - \max_i \cos(e_s, e_m^{(i)})
$$

This ensures that **lower similarity to existing ideas → higher novelty**.

---

#### **Sustainability Alignment**

$$
\text{Sustainability\ Alignment} =
\begin{cases}
1, & \text{if startup aligns with at least one UN SDG} \\
0, & \text{otherwise}
\end{cases}
$$

---

### **(c) Perceptual Features**

#### **Sentiment Score (FinBERT)**

FinBERT outputs probabilities for three classes:

$$
[p_\text{pos}, p_\text{neg}, p_\text{neu}]
$$

We map these to a scalar sentiment score:

$$
\text{Sentiment} = p_\text{pos} - p_\text{neg}
$$

Result is in range $[-1, 1]$.

#### **Social Buzz Score**

If we have engagement counts (likes, shares, mentions), we normalize:

$$
\text{Buzz Score} = \frac{\text{Current Engagement Count}}{\text{Max Engagement in Dataset}}
$$

This ensures values are in range $[0,1]$.

---

## **3️ Model Mathematics (SVM with RBF Kernel)**

We use a **Support Vector Classifier** with **Radial Basis Function (RBF)** kernel:

### **(a) RBF Kernel**

$$
K(x_i, x_j) = \exp\left(-\gamma \| x_i - x_j \|^2 \right)
$$

* $\gamma$ controls the influence of a single sample (higher = more complex boundary).

---

### **(b) SVM Decision Function**

The classifier finds a decision boundary:

$$
f(x) = \sum_{i=1}^N \alpha_i y_i K(x_i, x) + b
$$

Where:

* $\alpha_i$ = learned support vector coefficients
* $b$ = bias term
* $y_i \in \{-1, 1\}$ = class labels

---

### **(c) Probability Calibration**

We get decision scores $f(x)$ and convert to probabilities $p$ using **Platt scaling**:

$$
p(y=1|x) = \frac{1}{1 + \exp(A f(x) + B)}
$$

where $A$ and $B$ are fitted from validation data.

---

### **(d) VC Risk-Aligned Thresholding**

Instead of default $0.5$, we use $t = 0.58$ to reflect a VC's preference for reducing false positives:

$$
\hat{y} =
\begin{cases}
1, & p(y=1|x) \geq 0.58 \\
0, & \text{otherwise}
\end{cases}
$$

---

## **4️ Model Fine-Tuning Mathematics**

We fine-tune:

1. **Features** using **Recursive Feature Elimination with Cross Validation (RFECV)** — eliminates least important features iteratively.
2. **Hyperparameters** $C$ and $\gamma$ using **GridSearchCV**:

   * $C$ = regularization (larger = less regularization, more complex model)
   * $\gamma$ = kernel spread parameter

Grid search:

$$
(C, \gamma) \in \{0.5, 1, 2, 5\} \times \{\text{scale}, 0.1, 0.01, 0.001\}
$$

---

## **5️ Evaluation Metrics**

* **Accuracy**:

$$
\text{Accuracy} = \frac{\text{TP + TN}}{\text{TP + TN + FP + FN}}
$$

* **F1-score** (harmonic mean of precision and recall):

$$
F1 = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

* **Precision**:

$$
\text{Precision} = \frac{\text{TP}}{\text{TP + FP}}
$$

* **Recall**:

$$
\text{Recall} = \frac{\text{TP}}{\text{TP + FN}}
$$

---

## **6️ End-to-End Pipeline**

1. **Input**: Startup data (financial, strategic, perceptual features).
2. **Feature Engineering**:

   * Calculate novelty (SBERT cosine similarity).
   * Calculate sentiment (FinBERT probabilities).
   * Normalize numerical KPIs.
3. **Model**: RBF SVM with calibrated probabilities.
4. **Decision**: Apply VC threshold (0.58) for classification.
5. **Output**:

   * Probability of investment readiness.
   * Binary decision (Ready / Not Ready).
